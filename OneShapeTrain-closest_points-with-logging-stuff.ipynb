{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2142cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time, datetime\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "from src import config, data\n",
    "from src.checkpoints import CheckpointIO\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('testrun')\n",
    "cfg = config.load_config('configs/pointcloud/grid.yaml', 'configs/default.yaml')\n",
    "is_cuda = (torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Shorthands\n",
    "out_dir = cfg['training']['out_dir']\n",
    "batch_size = cfg['training']['batch_size']\n",
    "backup_every = cfg['training']['backup_every']\n",
    "vis_n_outputs = cfg['generation']['vis_n_outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dfcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "shutil.copyfile('configs/pointcloud/grid.yaml', os.path.join(out_dir, 'config.yaml'))\n",
    "\n",
    "# Dataset\n",
    "train_dataset = config.get_dataset('train', cfg)\n",
    "val_dataset = config.get_dataset('val', cfg, return_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42160475",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9d7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset[5], batch_size=batch_size, num_workers=cfg['training']['n_workers'], shuffle=True,\n",
    "#     collate_fn=data.collate_remove_none,\n",
    "#     worker_init_fn=data.worker_init_fn)\n",
    "\n",
    "# print(len(train_loader))    \n",
    "# print(train_loader)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset, batch_size=1, num_workers=cfg['training']['n_workers_val'], shuffle=False,\n",
    "#      collate_fn=data.collate_remove_none,\n",
    "#      worker_init_fn=data.worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60799253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code subset\n",
    "train_dataset = config.get_dataset(\"train\", cfg)\n",
    "ds = torch.utils.data.Subset(train_dataset, indices= [0]*len(train_dataset))\n",
    "val_dataset = config.get_dataset(\"val\", cfg)\n",
    "val_ds = torch.utils.data.Subset(val_dataset, indices= [0]*len(val_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=32, num_workers=8, shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     ds, batch_size=1, num_workers=8, shuffle=True,\n",
    "#     collate_fn=data.collate_remove_none,\n",
    "#     worker_init_fn=data.worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf4b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = config.get_model(cfg, device=device, dataset=train_dataset)\n",
    "\n",
    "# Generator\n",
    "generator = config.get_generator(model, cfg, device=device)\n",
    "\n",
    "# Intialize training\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "trainer = config.get_trainer(model, optimizer, cfg, device=device)\n",
    "\n",
    "checkpoint_io = CheckpointIO(out_dir, model=model, optimizer=optimizer)\n",
    "# try:\n",
    "#     load_dict = checkpoint_io.load('model.pt')\n",
    "# except FileExistsError:\n",
    "#     load_dict = dict()\n",
    "# epoch_it = load_dict.get('epoch_it', 0)\n",
    "# it = load_dict.get('it', 0)\n",
    "# metric_val_best = load_dict.get(\n",
    "#      'loss_val_best', -model_selection_sign * np.inf)\n",
    "\n",
    "# if metric_val_best == np.inf or metric_val_best == -np.inf:\n",
    "#     metric_val_best = -model_selection_sign * np.inf\n",
    "# print('Current best validation metric (%s): %.8f'\n",
    "#       % (model_selection_metric, metric_val_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0f2ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1978275\n",
      "output path:  out/pointcloud/grid\n"
     ]
    }
   ],
   "source": [
    "# Shorthands\n",
    "print_every = cfg['training']['print_every']\n",
    "checkpoint_every = cfg['training']['checkpoint_every']\n",
    "validate_every = cfg['training']['validate_every']\n",
    "visualize_every = cfg['training']['visualize_every']\n",
    "\n",
    "# Print model\n",
    "nparameters = sum(p.numel() for p in model.parameters())\n",
    "print('Total number of parameters: %d' % nparameters)\n",
    "\n",
    "print('output path: ', cfg['training']['out_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5e936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = model.encode_inputs(batch.get('inputs').cuda())\n",
    "# results = model.decode(batch.get('points').cuda(), c).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418a568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05e2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc831ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100] it=100, loss=0.9952, time: 75.24s, 10:58\n",
      "[Epoch 200] it=200, loss=-0.2721, time: 136.70s, 10:59\n",
      "Saving checkpoint\n",
      "[Epoch 300] it=300, loss=0.3416, time: 198.77s, 11:00\n",
      "[Epoch 400] it=400, loss=0.2693, time: 262.06s, 11:01\n",
      "Saving checkpoint\n",
      "[Epoch 500] it=500, loss=0.4456, time: 325.89s, 11:02\n",
      "[Epoch 600] it=600, loss=0.5506, time: 390.20s, 11:03\n",
      "Saving checkpoint\n",
      "[Epoch 700] it=700, loss=0.9491, time: 454.24s, 11:04\n",
      "[Epoch 800] it=800, loss=0.9850, time: 517.54s, 11:05\n",
      "Saving checkpoint\n",
      "[Epoch 900] it=900, loss=0.5740, time: 580.04s, 11:06\n",
      "[Epoch 1000] it=1000, loss=0.6208, time: 642.25s, 11:07\n",
      "Saving checkpoint\n",
      "[Epoch 1100] it=1100, loss=0.6259, time: 704.15s, 11:08\n",
      "[Epoch 1200] it=1200, loss=0.8625, time: 766.26s, 11:09\n",
      "Saving checkpoint\n",
      "[Epoch 1300] it=1300, loss=1.0999, time: 828.68s, 11:10\n",
      "[Epoch 1400] it=1400, loss=0.8184, time: 890.60s, 11:11\n",
      "Saving checkpoint\n",
      "[Epoch 1500] it=1500, loss=1.0128, time: 953.03s, 11:12\n",
      "[Epoch 1600] it=1600, loss=0.8648, time: 1015.44s, 11:13\n",
      "Saving checkpoint\n",
      "[Epoch 1700] it=1700, loss=1.4128, time: 1077.92s, 11:14\n",
      "[Epoch 1800] it=1800, loss=0.8108, time: 1140.36s, 11:15\n",
      "Saving checkpoint\n",
      "[Epoch 1900] it=1900, loss=0.9907, time: 1202.81s, 11:17\n",
      "[Epoch 2000] it=2000, loss=0.4727, time: 1264.97s, 11:18\n",
      "Saving checkpoint\n",
      "[Epoch 2100] it=2100, loss=0.8998, time: 1327.20s, 11:19\n",
      "[Epoch 2200] it=2200, loss=0.9327, time: 1389.44s, 11:20\n",
      "Saving checkpoint\n",
      "[Epoch 2300] it=2300, loss=0.3013, time: 1451.72s, 11:21\n",
      "[Epoch 2400] it=2400, loss=0.9274, time: 1513.97s, 11:22\n",
      "Saving checkpoint\n",
      "[Epoch 2500] it=2500, loss=1.0310, time: 1576.83s, 11:23\n",
      "[Epoch 2600] it=2600, loss=0.7635, time: 1639.82s, 11:24\n",
      "Saving checkpoint\n",
      "[Epoch 2700] it=2700, loss=1.1383, time: 1702.25s, 11:25\n",
      "[Epoch 2800] it=2800, loss=0.7129, time: 1764.50s, 11:26\n",
      "Saving checkpoint\n",
      "[Epoch 2900] it=2900, loss=0.4993, time: 1826.45s, 11:27\n",
      "[Epoch 3000] it=3000, loss=0.6353, time: 1888.80s, 11:28\n",
      "Saving checkpoint\n",
      "[Epoch 3100] it=3100, loss=1.3150, time: 1951.45s, 11:29\n",
      "[Epoch 3200] it=3200, loss=0.8899, time: 2013.51s, 11:30\n",
      "Saving checkpoint\n",
      "[Epoch 3300] it=3300, loss=0.7495, time: 2075.17s, 11:31\n",
      "[Epoch 3400] it=3400, loss=0.4424, time: 2136.59s, 11:32\n",
      "Saving checkpoint\n",
      "[Epoch 3500] it=3500, loss=0.5217, time: 2198.02s, 11:33\n",
      "[Epoch 3600] it=3600, loss=0.7393, time: 2259.18s, 11:34\n",
      "Saving checkpoint\n",
      "[Epoch 3700] it=3700, loss=0.9486, time: 2320.60s, 11:35\n",
      "[Epoch 3800] it=3800, loss=0.7065, time: 2381.65s, 11:36\n",
      "Saving checkpoint\n",
      "[Epoch 3900] it=3900, loss=0.4488, time: 2442.88s, 11:37\n",
      "[Epoch 4000] it=4000, loss=0.7077, time: 2504.24s, 11:38\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 4100] it=4100, loss=0.4654, time: 2565.74s, 11:39\n",
      "[Epoch 4200] it=4200, loss=0.4387, time: 2627.17s, 11:40\n",
      "Saving checkpoint\n",
      "[Epoch 4300] it=4300, loss=0.8119, time: 2688.51s, 11:41\n",
      "[Epoch 4400] it=4400, loss=0.2201, time: 2749.77s, 11:42\n",
      "Saving checkpoint\n",
      "[Epoch 4500] it=4500, loss=1.4273, time: 2811.10s, 11:43\n",
      "[Epoch 4600] it=4600, loss=0.3287, time: 2872.58s, 11:44\n",
      "Saving checkpoint\n",
      "[Epoch 4700] it=4700, loss=0.5079, time: 2933.56s, 11:45\n",
      "[Epoch 4800] it=4800, loss=0.8832, time: 2994.38s, 11:46\n",
      "Saving checkpoint\n",
      "[Epoch 4900] it=4900, loss=0.4064, time: 3055.24s, 11:47\n",
      "[Epoch 5000] it=5000, loss=1.2793, time: 3116.09s, 11:48\n",
      "Saving checkpoint\n",
      "[Epoch 5100] it=5100, loss=0.3018, time: 3177.69s, 11:49\n",
      "[Epoch 5200] it=5200, loss=0.5872, time: 3238.93s, 11:50\n",
      "Saving checkpoint\n",
      "[Epoch 5300] it=5300, loss=0.4268, time: 3300.37s, 11:51\n",
      "[Epoch 5400] it=5400, loss=0.6599, time: 3361.67s, 11:52\n",
      "Saving checkpoint\n",
      "[Epoch 5500] it=5500, loss=0.4102, time: 3423.04s, 11:54\n",
      "[Epoch 5600] it=5600, loss=0.3404, time: 3484.48s, 11:55\n",
      "Saving checkpoint\n",
      "[Epoch 5700] it=5700, loss=0.5655, time: 3545.71s, 11:56\n",
      "[Epoch 5800] it=5800, loss=0.5193, time: 3607.13s, 11:57\n",
      "Saving checkpoint\n",
      "[Epoch 5900] it=5900, loss=0.6548, time: 3668.61s, 11:58\n",
      "[Epoch 6000] it=6000, loss=0.5375, time: 3730.02s, 11:59\n",
      "Saving checkpoint\n",
      "[Epoch 6100] it=6100, loss=0.6060, time: 3791.34s, 12:00\n",
      "[Epoch 6200] it=6200, loss=0.5782, time: 3852.69s, 12:01\n",
      "Saving checkpoint\n",
      "[Epoch 6300] it=6300, loss=0.3597, time: 3914.16s, 12:02\n",
      "[Epoch 6400] it=6400, loss=0.4998, time: 3975.59s, 12:03\n",
      "Saving checkpoint\n",
      "[Epoch 6500] it=6500, loss=0.4325, time: 4037.08s, 12:04\n",
      "[Epoch 6600] it=6600, loss=0.2056, time: 4098.54s, 12:05\n",
      "Saving checkpoint\n",
      "[Epoch 6700] it=6700, loss=0.2668, time: 4160.35s, 12:06\n",
      "[Epoch 6800] it=6800, loss=1.2617, time: 4222.08s, 12:07\n",
      "Saving checkpoint\n",
      "[Epoch 6900] it=6900, loss=0.3657, time: 4283.91s, 12:08\n",
      "[Epoch 7000] it=7000, loss=0.5635, time: 4345.86s, 12:09\n",
      "Saving checkpoint\n",
      "[Epoch 7100] it=7100, loss=0.6621, time: 4407.80s, 12:10\n",
      "[Epoch 7200] it=7200, loss=0.3643, time: 4469.70s, 12:11\n",
      "Saving checkpoint\n",
      "[Epoch 7300] it=7300, loss=3.1901, time: 4531.82s, 12:12\n",
      "[Epoch 7400] it=7400, loss=0.5074, time: 4593.74s, 12:13\n",
      "Saving checkpoint\n",
      "[Epoch 7500] it=7500, loss=0.4820, time: 4655.86s, 12:14\n",
      "[Epoch 7600] it=7600, loss=0.5458, time: 4717.88s, 12:15\n",
      "Saving checkpoint\n",
      "[Epoch 7700] it=7700, loss=0.0245, time: 4780.06s, 12:16\n",
      "[Epoch 7800] it=7800, loss=0.2304, time: 4841.97s, 12:17\n",
      "Saving checkpoint\n",
      "[Epoch 7900] it=7900, loss=0.4078, time: 4904.08s, 12:18\n",
      "[Epoch 8000] it=8000, loss=0.3548, time: 4966.27s, 12:19\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 8100] it=8100, loss=0.4663, time: 5028.61s, 12:20\n",
      "[Epoch 8200] it=8200, loss=0.1642, time: 5090.45s, 12:21\n",
      "Saving checkpoint\n",
      "[Epoch 8300] it=8300, loss=0.2586, time: 5152.00s, 12:22\n",
      "[Epoch 8400] it=8400, loss=0.2905, time: 5213.72s, 12:23\n",
      "Saving checkpoint\n",
      "[Epoch 8500] it=8500, loss=0.5546, time: 5275.84s, 12:24\n",
      "[Epoch 8600] it=8600, loss=0.5658, time: 5337.87s, 12:25\n",
      "Saving checkpoint\n",
      "[Epoch 8700] it=8700, loss=0.4429, time: 5400.01s, 12:26\n",
      "[Epoch 8800] it=8800, loss=0.1360, time: 5462.02s, 12:27\n",
      "Saving checkpoint\n",
      "[Epoch 8900] it=8900, loss=0.5933, time: 5524.13s, 12:29\n",
      "[Epoch 9000] it=9000, loss=0.6428, time: 5586.19s, 12:30\n",
      "Saving checkpoint\n",
      "[Epoch 9100] it=9100, loss=0.4718, time: 5648.29s, 12:31\n",
      "[Epoch 9200] it=9200, loss=0.5014, time: 5709.34s, 12:32\n",
      "Saving checkpoint\n",
      "[Epoch 9300] it=9300, loss=0.5272, time: 5771.00s, 12:33\n",
      "[Epoch 9400] it=9400, loss=0.4042, time: 5832.55s, 12:34\n",
      "Saving checkpoint\n",
      "[Epoch 9500] it=9500, loss=0.5893, time: 5894.15s, 12:35\n",
      "[Epoch 9600] it=9600, loss=0.4957, time: 5955.58s, 12:36\n",
      "Saving checkpoint\n",
      "[Epoch 9700] it=9700, loss=0.3443, time: 6017.06s, 12:37\n",
      "[Epoch 9800] it=9800, loss=0.3712, time: 6078.53s, 12:38\n",
      "Saving checkpoint\n",
      "[Epoch 9900] it=9900, loss=0.4509, time: 6140.16s, 12:39\n",
      "[Epoch 10000] it=10000, loss=0.2749, time: 6201.61s, 12:40\n",
      "Saving checkpoint\n",
      "[Epoch 10100] it=10100, loss=0.8858, time: 6263.19s, 12:41\n",
      "[Epoch 10200] it=10200, loss=0.4422, time: 6324.64s, 12:42\n",
      "Saving checkpoint\n",
      "[Epoch 10300] it=10300, loss=0.8379, time: 6386.13s, 12:43\n",
      "[Epoch 10400] it=10400, loss=0.7329, time: 6447.60s, 12:44\n",
      "Saving checkpoint\n",
      "[Epoch 10500] it=10500, loss=0.7302, time: 6509.22s, 12:45\n",
      "[Epoch 10600] it=10600, loss=0.5230, time: 6570.67s, 12:46\n",
      "Saving checkpoint\n",
      "[Epoch 10700] it=10700, loss=0.4902, time: 6632.29s, 12:47\n",
      "[Epoch 10800] it=10800, loss=-0.2369, time: 6693.77s, 12:48\n",
      "Saving checkpoint\n",
      "[Epoch 10900] it=10900, loss=0.7533, time: 6755.43s, 12:49\n",
      "[Epoch 11000] it=11000, loss=0.7007, time: 6816.75s, 12:50\n",
      "Saving checkpoint\n",
      "[Epoch 11100] it=11100, loss=0.5437, time: 6878.25s, 12:51\n",
      "[Epoch 11200] it=11200, loss=0.7292, time: 6939.69s, 12:52\n",
      "Saving checkpoint\n",
      "[Epoch 11300] it=11300, loss=0.6416, time: 7001.33s, 12:53\n",
      "[Epoch 11400] it=11400, loss=0.7408, time: 7062.78s, 12:54\n",
      "Saving checkpoint\n",
      "[Epoch 11500] it=11500, loss=0.6300, time: 7123.57s, 12:55\n",
      "[Epoch 11600] it=11600, loss=0.4390, time: 7184.79s, 12:56\n",
      "Saving checkpoint\n",
      "[Epoch 11700] it=11700, loss=0.5825, time: 7246.32s, 12:57\n",
      "[Epoch 11800] it=11800, loss=0.5670, time: 7307.78s, 12:58\n",
      "Saving checkpoint\n",
      "[Epoch 11900] it=11900, loss=0.7009, time: 7369.37s, 12:59\n",
      "[Epoch 12000] it=12000, loss=0.7308, time: 7430.80s, 13:00\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 12100] it=12100, loss=0.6158, time: 7492.37s, 13:01\n",
      "[Epoch 12200] it=12200, loss=0.7296, time: 7553.61s, 13:02\n",
      "Saving checkpoint\n",
      "[Epoch 12300] it=12300, loss=0.3884, time: 7614.93s, 13:03\n",
      "[Epoch 12400] it=12400, loss=0.6685, time: 7676.35s, 13:04\n",
      "Saving checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12500] it=12500, loss=0.5276, time: 7737.95s, 13:05\n",
      "[Epoch 12600] it=12600, loss=0.5927, time: 7799.43s, 13:06\n",
      "Saving checkpoint\n",
      "[Epoch 12700] it=12700, loss=0.6644, time: 7861.04s, 13:07\n",
      "[Epoch 12800] it=12800, loss=0.2762, time: 7922.51s, 13:09\n",
      "Saving checkpoint\n",
      "[Epoch 12900] it=12900, loss=0.5897, time: 7984.12s, 13:10\n",
      "[Epoch 13000] it=13000, loss=0.5606, time: 8045.55s, 13:11\n",
      "Saving checkpoint\n",
      "[Epoch 13100] it=13100, loss=0.5699, time: 8106.83s, 13:12\n",
      "[Epoch 13200] it=13200, loss=0.6254, time: 8168.20s, 13:13\n",
      "Saving checkpoint\n",
      "[Epoch 13300] it=13300, loss=0.6315, time: 8229.50s, 13:14\n",
      "[Epoch 13400] it=13400, loss=0.6253, time: 8290.91s, 13:15\n",
      "Saving checkpoint\n",
      "[Epoch 13500] it=13500, loss=0.5627, time: 8352.39s, 13:16\n",
      "[Epoch 13600] it=13600, loss=0.6806, time: 8413.83s, 13:17\n",
      "Saving checkpoint\n",
      "[Epoch 13700] it=13700, loss=0.6160, time: 8475.43s, 13:18\n",
      "[Epoch 13800] it=13800, loss=0.5426, time: 8536.88s, 13:19\n",
      "Saving checkpoint\n",
      "[Epoch 13900] it=13900, loss=0.5299, time: 8599.44s, 13:20\n",
      "[Epoch 14000] it=14000, loss=0.4542, time: 8661.24s, 13:21\n",
      "Saving checkpoint\n",
      "[Epoch 14100] it=14100, loss=0.4330, time: 8722.63s, 13:22\n",
      "[Epoch 14200] it=14200, loss=0.4563, time: 8784.01s, 13:23\n",
      "Saving checkpoint\n",
      "[Epoch 14300] it=14300, loss=0.6664, time: 8845.75s, 13:24\n",
      "[Epoch 14400] it=14400, loss=0.5125, time: 8907.44s, 13:25\n",
      "Saving checkpoint\n",
      "[Epoch 14500] it=14500, loss=0.6059, time: 8969.11s, 13:26\n",
      "[Epoch 14600] it=14600, loss=0.4106, time: 9030.92s, 13:27\n",
      "Saving checkpoint\n",
      "[Epoch 14700] it=14700, loss=0.8217, time: 9092.80s, 13:28\n",
      "[Epoch 14800] it=14800, loss=0.5416, time: 9154.47s, 13:29\n",
      "Saving checkpoint\n",
      "[Epoch 14900] it=14900, loss=0.3881, time: 9216.28s, 13:30\n",
      "[Epoch 15000] it=15000, loss=0.3388, time: 9278.01s, 13:31\n",
      "Saving checkpoint\n",
      "[Epoch 15100] it=15100, loss=0.7157, time: 9339.60s, 13:32\n",
      "[Epoch 15200] it=15200, loss=0.6800, time: 9401.40s, 13:33\n",
      "Saving checkpoint\n",
      "[Epoch 15300] it=15300, loss=0.7465, time: 9463.09s, 13:34\n",
      "[Epoch 15400] it=15400, loss=0.7117, time: 9524.73s, 13:35\n",
      "Saving checkpoint\n",
      "[Epoch 15500] it=15500, loss=0.5305, time: 9586.50s, 13:36\n",
      "[Epoch 15600] it=15600, loss=0.5397, time: 9648.04s, 13:37\n",
      "Saving checkpoint\n",
      "[Epoch 15700] it=15700, loss=0.4545, time: 9709.60s, 13:38\n",
      "[Epoch 15800] it=15800, loss=0.8779, time: 9771.05s, 13:39\n",
      "Saving checkpoint\n",
      "[Epoch 15900] it=15900, loss=0.5103, time: 9832.72s, 13:40\n",
      "[Epoch 16000] it=16000, loss=0.4703, time: 9894.11s, 13:41\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 16100] it=16100, loss=0.5875, time: 9955.73s, 13:42\n",
      "[Epoch 16200] it=16200, loss=0.4863, time: 10017.21s, 13:43\n",
      "Saving checkpoint\n",
      "[Epoch 16300] it=16300, loss=0.5197, time: 10078.87s, 13:44\n",
      "[Epoch 16400] it=16400, loss=0.4339, time: 10140.33s, 13:45\n",
      "Saving checkpoint\n",
      "[Epoch 16500] it=16500, loss=0.0971, time: 10201.93s, 13:46\n",
      "[Epoch 16600] it=16600, loss=0.2769, time: 10263.38s, 13:48\n",
      "Saving checkpoint\n",
      "[Epoch 16700] it=16700, loss=0.4247, time: 10325.02s, 13:49\n",
      "[Epoch 16800] it=16800, loss=0.1679, time: 10386.47s, 13:50\n",
      "Saving checkpoint\n",
      "[Epoch 16900] it=16900, loss=0.4212, time: 10448.09s, 13:51\n",
      "[Epoch 17000] it=17000, loss=0.4436, time: 10509.54s, 13:52\n",
      "Saving checkpoint\n",
      "[Epoch 17100] it=17100, loss=0.2141, time: 10571.17s, 13:53\n",
      "[Epoch 17200] it=17200, loss=0.5050, time: 10632.15s, 13:54\n",
      "Saving checkpoint\n",
      "[Epoch 17300] it=17300, loss=0.5058, time: 10693.70s, 13:55\n",
      "[Epoch 17400] it=17400, loss=0.5612, time: 10755.13s, 13:56\n",
      "Saving checkpoint\n",
      "[Epoch 17500] it=17500, loss=0.8494, time: 10816.77s, 13:57\n",
      "[Epoch 17600] it=17600, loss=0.2229, time: 10878.25s, 13:58\n",
      "Saving checkpoint\n",
      "[Epoch 17700] it=17700, loss=0.5707, time: 10939.85s, 13:59\n",
      "[Epoch 17800] it=17800, loss=0.4564, time: 10999.08s, 14:00\n",
      "Saving checkpoint\n",
      "[Epoch 17900] it=17900, loss=0.4791, time: 11060.62s, 14:01\n",
      "[Epoch 18000] it=18000, loss=0.5237, time: 11121.21s, 14:02\n",
      "Saving checkpoint\n",
      "[Epoch 18100] it=18100, loss=0.5031, time: 11182.66s, 14:03\n",
      "[Epoch 18200] it=18200, loss=0.3085, time: 11244.11s, 14:04\n",
      "Saving checkpoint\n",
      "[Epoch 18300] it=18300, loss=0.5976, time: 11305.55s, 14:05\n",
      "[Epoch 18400] it=18400, loss=-0.0287, time: 11366.98s, 14:06\n",
      "Saving checkpoint\n",
      "[Epoch 18500] it=18500, loss=0.4833, time: 11428.43s, 14:07\n",
      "[Epoch 18600] it=18600, loss=0.3994, time: 11489.87s, 14:08\n",
      "Saving checkpoint\n",
      "[Epoch 18700] it=18700, loss=0.4791, time: 11551.38s, 14:09\n",
      "[Epoch 18800] it=18800, loss=0.5775, time: 11612.82s, 14:10\n",
      "Saving checkpoint\n",
      "[Epoch 18900] it=18900, loss=0.5318, time: 11674.43s, 14:11\n",
      "[Epoch 19000] it=19000, loss=0.4646, time: 11735.90s, 14:12\n",
      "Saving checkpoint\n",
      "[Epoch 19100] it=19100, loss=0.3285, time: 11797.52s, 14:13\n",
      "[Epoch 19200] it=19200, loss=0.5583, time: 11858.97s, 14:14\n",
      "Saving checkpoint\n",
      "[Epoch 19300] it=19300, loss=0.5831, time: 11920.60s, 14:15\n",
      "[Epoch 19400] it=19400, loss=0.5786, time: 11982.06s, 14:16\n",
      "Saving checkpoint\n",
      "[Epoch 19500] it=19500, loss=0.2854, time: 12043.64s, 14:17\n",
      "[Epoch 19600] it=19600, loss=0.3903, time: 12105.11s, 14:18\n",
      "Saving checkpoint\n",
      "[Epoch 19700] it=19700, loss=0.5648, time: 12166.71s, 14:19\n",
      "[Epoch 19800] it=19800, loss=0.4505, time: 12228.22s, 14:20\n",
      "Saving checkpoint\n",
      "[Epoch 19900] it=19900, loss=0.5891, time: 12289.80s, 14:21\n",
      "[Epoch 20000] it=20000, loss=0.5927, time: 12351.26s, 14:22\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 20100] it=20100, loss=0.5785, time: 12412.96s, 14:23\n",
      "[Epoch 20200] it=20200, loss=0.5484, time: 12474.80s, 14:24\n",
      "Saving checkpoint\n",
      "[Epoch 20300] it=20300, loss=0.6427, time: 12536.58s, 14:25\n",
      "[Epoch 20400] it=20400, loss=0.4640, time: 12598.11s, 14:26\n",
      "Saving checkpoint\n",
      "[Epoch 20500] it=20500, loss=0.4091, time: 12659.72s, 14:27\n",
      "[Epoch 20600] it=20600, loss=0.5789, time: 12721.18s, 14:28\n",
      "Saving checkpoint\n",
      "[Epoch 20700] it=20700, loss=0.2055, time: 12782.84s, 14:30\n",
      "[Epoch 20800] it=20800, loss=0.6023, time: 12843.36s, 14:31\n",
      "Saving checkpoint\n",
      "[Epoch 20900] it=20900, loss=0.6131, time: 12904.04s, 14:32\n",
      "[Epoch 21000] it=21000, loss=0.8247, time: 12965.07s, 14:33\n",
      "Saving checkpoint\n",
      "[Epoch 21100] it=21100, loss=0.5089, time: 13026.80s, 14:34\n",
      "[Epoch 21200] it=21200, loss=0.6328, time: 13088.21s, 14:35\n",
      "Saving checkpoint\n",
      "[Epoch 21300] it=21300, loss=0.4677, time: 13149.60s, 14:36\n",
      "[Epoch 21400] it=21400, loss=0.4033, time: 13211.03s, 14:37\n",
      "Saving checkpoint\n",
      "[Epoch 21500] it=21500, loss=0.5108, time: 13272.19s, 14:38\n",
      "[Epoch 21600] it=21600, loss=0.4648, time: 13333.42s, 14:39\n",
      "Saving checkpoint\n",
      "[Epoch 21700] it=21700, loss=0.5865, time: 13394.70s, 14:40\n",
      "[Epoch 21800] it=21800, loss=0.5030, time: 13456.38s, 14:41\n",
      "Saving checkpoint\n",
      "[Epoch 21900] it=21900, loss=0.5072, time: 13518.15s, 14:42\n",
      "[Epoch 22000] it=22000, loss=0.4513, time: 13579.72s, 14:43\n",
      "Saving checkpoint\n",
      "[Epoch 22100] it=22100, loss=0.4582, time: 13641.36s, 14:44\n",
      "[Epoch 22200] it=22200, loss=0.4564, time: 13702.77s, 14:45\n",
      "Saving checkpoint\n",
      "[Epoch 22300] it=22300, loss=0.5386, time: 13764.47s, 14:46\n",
      "[Epoch 22400] it=22400, loss=0.5952, time: 13826.10s, 14:47\n",
      "Saving checkpoint\n",
      "[Epoch 22500] it=22500, loss=0.4904, time: 13887.88s, 14:48\n",
      "[Epoch 22600] it=22600, loss=0.5044, time: 13949.59s, 14:49\n",
      "Saving checkpoint\n",
      "[Epoch 22700] it=22700, loss=0.2949, time: 14011.20s, 14:50\n",
      "[Epoch 22800] it=22800, loss=0.4839, time: 14072.98s, 14:51\n",
      "Saving checkpoint\n",
      "[Epoch 22900] it=22900, loss=0.4209, time: 14134.70s, 14:52\n",
      "[Epoch 23000] it=23000, loss=0.4371, time: 14196.36s, 14:53\n",
      "Saving checkpoint\n",
      "[Epoch 23100] it=23100, loss=0.5192, time: 14258.01s, 14:54\n",
      "[Epoch 23200] it=23200, loss=0.5653, time: 14319.57s, 14:55\n",
      "Saving checkpoint\n",
      "[Epoch 23300] it=23300, loss=0.3602, time: 14381.48s, 14:56\n",
      "[Epoch 23400] it=23400, loss=-0.0485, time: 14443.31s, 14:57\n",
      "Saving checkpoint\n",
      "[Epoch 23500] it=23500, loss=0.6910, time: 14505.20s, 14:58\n",
      "[Epoch 23600] it=23600, loss=0.5494, time: 14566.94s, 14:59\n",
      "Saving checkpoint\n",
      "[Epoch 23700] it=23700, loss=0.4993, time: 14628.70s, 15:00\n",
      "[Epoch 23800] it=23800, loss=0.3935, time: 14690.26s, 15:01\n",
      "Saving checkpoint\n",
      "[Epoch 23900] it=23900, loss=0.4891, time: 14751.91s, 15:02\n",
      "[Epoch 24000] it=24000, loss=0.3911, time: 14813.43s, 15:03\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 24100] it=24100, loss=0.1936, time: 14875.05s, 15:04\n",
      "[Epoch 24200] it=24200, loss=0.4528, time: 14936.47s, 15:05\n",
      "Saving checkpoint\n",
      "[Epoch 24300] it=24300, loss=0.4819, time: 14998.14s, 15:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24400] it=24400, loss=0.5835, time: 15059.83s, 15:07\n",
      "Saving checkpoint\n",
      "[Epoch 24500] it=24500, loss=0.3140, time: 15121.70s, 15:08\n",
      "[Epoch 24600] it=24600, loss=0.5503, time: 15183.66s, 15:10\n",
      "Saving checkpoint\n",
      "[Epoch 24700] it=24700, loss=-0.1906, time: 15245.65s, 15:11\n",
      "[Epoch 24800] it=24800, loss=0.4754, time: 15307.24s, 15:12\n",
      "Saving checkpoint\n",
      "[Epoch 24900] it=24900, loss=0.3623, time: 15369.09s, 15:13\n",
      "[Epoch 25000] it=25000, loss=-0.0596, time: 15430.86s, 15:14\n",
      "Saving checkpoint\n",
      "[Epoch 25100] it=25100, loss=0.2937, time: 15492.59s, 15:15\n",
      "[Epoch 25200] it=25200, loss=0.4947, time: 15554.36s, 15:16\n",
      "Saving checkpoint\n",
      "[Epoch 25300] it=25300, loss=0.3812, time: 15616.24s, 15:17\n",
      "[Epoch 25400] it=25400, loss=0.4960, time: 15678.00s, 15:18\n",
      "Saving checkpoint\n",
      "[Epoch 25500] it=25500, loss=0.5735, time: 15739.74s, 15:19\n",
      "[Epoch 25600] it=25600, loss=0.4496, time: 15801.20s, 15:20\n",
      "Saving checkpoint\n",
      "[Epoch 25700] it=25700, loss=0.2215, time: 15862.58s, 15:21\n",
      "[Epoch 25800] it=25800, loss=0.2765, time: 15924.07s, 15:22\n",
      "Saving checkpoint\n",
      "[Epoch 25900] it=25900, loss=0.6189, time: 15985.63s, 15:23\n",
      "[Epoch 26000] it=26000, loss=0.5020, time: 16047.31s, 15:24\n",
      "Saving checkpoint\n",
      "[Epoch 26100] it=26100, loss=0.7143, time: 16109.17s, 15:25\n",
      "[Epoch 26200] it=26200, loss=0.7999, time: 16170.83s, 15:26\n",
      "Saving checkpoint\n",
      "[Epoch 26300] it=26300, loss=0.7518, time: 16232.64s, 15:27\n",
      "[Epoch 26400] it=26400, loss=0.8172, time: 16294.14s, 15:28\n",
      "Saving checkpoint\n",
      "[Epoch 26500] it=26500, loss=0.7593, time: 16355.80s, 15:29\n",
      "[Epoch 26600] it=26600, loss=0.1067, time: 16417.44s, 15:30\n",
      "Saving checkpoint\n",
      "[Epoch 26700] it=26700, loss=0.0798, time: 16479.42s, 15:31\n",
      "[Epoch 26800] it=26800, loss=0.3334, time: 16541.27s, 15:32\n",
      "Saving checkpoint\n",
      "[Epoch 26900] it=26900, loss=-0.0643, time: 16603.13s, 15:33\n",
      "[Epoch 27000] it=27000, loss=0.3841, time: 16664.52s, 15:34\n",
      "Saving checkpoint\n",
      "[Epoch 27100] it=27100, loss=0.0027, time: 16726.46s, 15:35\n",
      "[Epoch 27200] it=27200, loss=0.5688, time: 16788.08s, 15:36\n",
      "Saving checkpoint\n",
      "[Epoch 27300] it=27300, loss=-1.0478, time: 16849.85s, 15:37\n",
      "[Epoch 27400] it=27400, loss=0.8829, time: 16911.30s, 15:38\n",
      "Saving checkpoint\n",
      "[Epoch 27500] it=27500, loss=0.3066, time: 16972.81s, 15:39\n",
      "[Epoch 27600] it=27600, loss=0.4965, time: 17034.22s, 15:40\n",
      "Saving checkpoint\n",
      "[Epoch 27700] it=27700, loss=0.5815, time: 17095.88s, 15:41\n",
      "[Epoch 27800] it=27800, loss=0.6127, time: 17157.38s, 15:42\n",
      "Saving checkpoint\n",
      "[Epoch 27900] it=27900, loss=0.6542, time: 17219.14s, 15:43\n",
      "[Epoch 28000] it=28000, loss=0.5292, time: 17280.64s, 15:44\n",
      "Saving checkpoint\n",
      "Backup checkpoint\n",
      "[Epoch 28100] it=28100, loss=0.1931, time: 17342.25s, 15:46\n",
      "[Epoch 28200] it=28200, loss=0.4084, time: 17403.67s, 15:47\n",
      "Saving checkpoint\n",
      "[Epoch 28300] it=28300, loss=0.3458, time: 17465.33s, 15:48\n",
      "[Epoch 28400] it=28400, loss=0.4197, time: 17526.79s, 15:49\n",
      "Saving checkpoint\n",
      "[Epoch 28500] it=28500, loss=0.4152, time: 17588.45s, 15:50\n",
      "[Epoch 28600] it=28600, loss=0.3938, time: 17649.92s, 15:51\n",
      "Saving checkpoint\n",
      "[Epoch 28700] it=28700, loss=0.4826, time: 17711.54s, 15:52\n",
      "[Epoch 28800] it=28800, loss=0.3612, time: 17773.13s, 15:53\n",
      "Saving checkpoint\n",
      "[Epoch 28900] it=28900, loss=0.3570, time: 17834.82s, 15:54\n",
      "[Epoch 29000] it=29000, loss=0.2734, time: 17895.84s, 15:55\n",
      "Saving checkpoint\n",
      "[Epoch 29100] it=29100, loss=0.4066, time: 17956.80s, 15:56\n",
      "[Epoch 29200] it=29200, loss=0.4550, time: 18017.37s, 15:57\n",
      "Saving checkpoint\n",
      "[Epoch 29300] it=29300, loss=0.4299, time: 18078.11s, 15:58\n",
      "[Epoch 29400] it=29400, loss=0.4425, time: 18138.59s, 15:59\n",
      "Saving checkpoint\n",
      "[Epoch 29500] it=29500, loss=0.3423, time: 18199.37s, 16:00\n",
      "[Epoch 29600] it=29600, loss=0.3686, time: 18260.03s, 16:01\n",
      "Saving checkpoint\n",
      "[Epoch 29700] it=29700, loss=0.2451, time: 18320.62s, 16:02\n",
      "[Epoch 29800] it=29800, loss=0.3291, time: 18379.98s, 16:03\n",
      "Saving checkpoint\n",
      "[Epoch 29900] it=29900, loss=0.2685, time: 18440.54s, 16:04\n",
      "[Epoch 30000] it=30000, loss=0.2989, time: 18501.03s, 16:05\n",
      "Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "epoch_it = 0\n",
    "batch = next(train_loader.__iter__())\n",
    "while epoch_it <= 30000:\n",
    "    epoch_it += 1\n",
    "\n",
    "    it += 1\n",
    "    loss = trainer.train_step(batch)\n",
    "    #logger.add_scalar('train/loss', loss, it)\n",
    "    writer.add_scalars(\"metropolis+sigma1\", {'global_loss':loss[0],\n",
    "                                        'norm_loss':loss[1],\n",
    "                                        'gradient_loss':loss[2], \n",
    "                                        'ratio_relu':loss[3]}, it)\n",
    "    \n",
    "    \n",
    "    #writer.add_scalar(\"dotProductReg\", loss[0], it)\n",
    "    # Print output\n",
    "    if print_every > 0 and (it % print_every) == 0:\n",
    "        t = datetime.datetime.now()\n",
    "        print('[Epoch %02d] it=%03d, loss=%.4f, time: %.2fs, %02d:%02d'\n",
    "                    % (epoch_it, it, loss[0], time.time() - t0, t.hour, t.minute))\n",
    "\n",
    "    #data_v = next(in data_vis_.__iter__())ist:\n",
    "    # Visualize output\n",
    "#     if visualize_every > 0 and (it % visualize_every) == 0:\n",
    "#         print('Visualizing')\n",
    "#         for data_vis in data_vis_list:\n",
    "#             if cfg['generation']['sliding_window']:\n",
    "#                 out = generator.generate_mesh_sliding(data_vis['data'])\n",
    "#             else:\n",
    "#                 out = generator.generate_mesh(data_vis['data'])\n",
    "#             # Get statistics\n",
    "#             try:\n",
    "#                 mesh, stats_dict = out\n",
    "#             except TypeError:\n",
    "#                 mesh, stats_dict = out, {}\n",
    "\n",
    "#             mesh.export(os.path.join(out_dir, 'vis', '{}_{}_{}.off'.format(it, data_vis['category'], data_vis['it'])))\n",
    "\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (checkpoint_every > 0 and (it % checkpoint_every) == 0):\n",
    "        print('Saving checkpoint')\n",
    "        checkpoint_io.save('metropolis+sigma1.pt', epoch_it=epoch_it, it=it)\n",
    "\n",
    "    # Backup if necessary\n",
    "    if (backup_every > 0 and (it % backup_every) == 0):\n",
    "        print('Backup checkpoint')\n",
    "        checkpoint_io.save('metropolis+sigma1Model_%d.pt' % it, epoch_it=epoch_it, it=it)\n",
    "        \n",
    "    # Run validation\n",
    "#     if validate_every > 0 and (it % validate_every) == 0:\n",
    "#         eval_dict = trainer.evaluate(val_loader)\n",
    "#         metric_val = eval_dict[model_selection_metric]\n",
    "#         print('Validation metric (%s): %.4f'\n",
    "#                 % (model_selection_metric, metric_val))\n",
    "\n",
    "#         for k, v in eval_dict.items():\n",
    "#             logger.add_scalar('val/%s' % k, v, it)\n",
    "\n",
    "#         if model_selection_sign * (metric_val - metric_val_best) > 0:\n",
    "#             metric_val_best = metric_val\n",
    "#             print('New best model (loss %.4f)' % metric_val_best)\n",
    "#             checkpoint_io.save('model_best.pt', epoch_it=epoch_it, it=it,\n",
    "#                                 loss_val_best=metric_val_best)\n",
    "\n",
    "    # Exit if necessary\n",
    "#     if exit_after > 0 and (time.time() - t0) >= exit_after:\n",
    "#         print('Time limit reached. Exiting.')\n",
    "#         checkpoint_io.save('model.pt', epoch_it=epoch_it, it=it,\n",
    "#                             loss_val_best=metric_val_best)\n",
    "\n",
    "#print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b4541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv_onet",
   "language": "python",
   "name": "conv_onet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
