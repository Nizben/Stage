{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2142cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time, datetime\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "from src import config, data\n",
    "from src.checkpoints import CheckpointIO\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('testrun')\n",
    "cfg = config.load_config('configs/pointcloud/grid.yaml', 'configs/default.yaml')\n",
    "is_cuda = (torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Shorthands\n",
    "out_dir = cfg['training']['out_dir']\n",
    "batch_size = cfg['training']['batch_size']\n",
    "backup_every = cfg['training']['backup_every']\n",
    "vis_n_outputs = cfg['generation']['vis_n_outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dfcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "shutil.copyfile('configs/pointcloud/grid.yaml', os.path.join(out_dir, 'config.yaml'))\n",
    "\n",
    "# Dataset\n",
    "train_dataset = config.get_dataset('train', cfg)\n",
    "val_dataset = config.get_dataset('val', cfg, return_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42160475",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9d7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset[5], batch_size=batch_size, num_workers=cfg['training']['n_workers'], shuffle=True,\n",
    "#     collate_fn=data.collate_remove_none,\n",
    "#     worker_init_fn=data.worker_init_fn)\n",
    "\n",
    "# print(len(train_loader))    \n",
    "# print(train_loader)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset, batch_size=1, num_workers=cfg['training']['n_workers_val'], shuffle=False,\n",
    "#      collate_fn=data.collate_remove_none,\n",
    "#      worker_init_fn=data.worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60799253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code subset\n",
    "train_dataset = config.get_dataset(\"train\", cfg)\n",
    "ds = torch.utils.data.Subset(train_dataset, indices= [0]*len(train_dataset))\n",
    "val_dataset = config.get_dataset(\"val\", cfg)\n",
    "val_ds = torch.utils.data.Subset(val_dataset, indices= [0]*len(val_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=32, num_workers=8, shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     ds, batch_size=1, num_workers=8, shuffle=True,\n",
    "#     collate_fn=data.collate_remove_none,\n",
    "#     worker_init_fn=data.worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf4b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = config.get_model(cfg, device=device, dataset=train_dataset)\n",
    "\n",
    "# Generator\n",
    "generator = config.get_generator(model, cfg, device=device)\n",
    "\n",
    "# Intialize training\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "trainer = config.get_trainer(model, optimizer, cfg, device=device)\n",
    "\n",
    "checkpoint_io = CheckpointIO(out_dir, model=model, optimizer=optimizer)\n",
    "# try:\n",
    "#     load_dict = checkpoint_io.load('model.pt')\n",
    "# except FileExistsError:\n",
    "#     load_dict = dict()\n",
    "# epoch_it = load_dict.get('epoch_it', 0)\n",
    "# it = load_dict.get('it', 0)\n",
    "# metric_val_best = load_dict.get(\n",
    "#      'loss_val_best', -model_selection_sign * np.inf)\n",
    "\n",
    "# if metric_val_best == np.inf or metric_val_best == -np.inf:\n",
    "#     metric_val_best = -model_selection_sign * np.inf\n",
    "# print('Current best validation metric (%s): %.8f'\n",
    "#       % (model_selection_metric, metric_val_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0f2ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1978275\n",
      "output path:  out/pointcloud/grid\n"
     ]
    }
   ],
   "source": [
    "# Shorthands\n",
    "print_every = cfg['training']['print_every']\n",
    "checkpoint_every = cfg['training']['checkpoint_every']\n",
    "validate_every = cfg['training']['validate_every']\n",
    "visualize_every = cfg['training']['visualize_every']\n",
    "\n",
    "# Print model\n",
    "nparameters = sum(p.numel() for p in model.parameters())\n",
    "print('Total number of parameters: %d' % nparameters)\n",
    "\n",
    "print('output path: ', cfg['training']['out_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5e936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = model.encode_inputs(batch.get('inputs').cuda())\n",
    "# results = model.decode(batch.get('points').cuda(), c).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418a568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05e2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc831ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "epoch_it = 0\n",
    "batch = next(train_loader.__iter__())\n",
    "while epoch_it <= 30000:\n",
    "    epoch_it += 1\n",
    "\n",
    "    it += 1\n",
    "    loss = trainer.train_step(batch)\n",
    "    #logger.add_scalar('train/loss', loss, it)\n",
    "    writer.add_scalars(\"metropolis+sigma1\", {'global_loss':loss[0],\n",
    "                                        'norm_loss':loss[1],\n",
    "                                        'gradient_loss':loss[2], \n",
    "                                        'ratio_relu':loss[3]}, it)\n",
    "    \n",
    "    \n",
    "    #writer.add_scalar(\"dotProductReg\", loss[0], it)\n",
    "    # Print output\n",
    "    if print_every > 0 and (it % print_every) == 0:\n",
    "        t = datetime.datetime.now()\n",
    "        print('[Epoch %02d] it=%03d, loss=%.4f, time: %.2fs, %02d:%02d'\n",
    "                    % (epoch_it, it, loss[0], time.time() - t0, t.hour, t.minute))\n",
    "\n",
    "    #data_v = next(in data_vis_.__iter__())ist:\n",
    "    # Visualize output\n",
    "#     if visualize_every > 0 and (it % visualize_every) == 0:\n",
    "#         print('Visualizing')\n",
    "#         for data_vis in data_vis_list:\n",
    "#             if cfg['generation']['sliding_window']:\n",
    "#                 out = generator.generate_mesh_sliding(data_vis['data'])\n",
    "#             else:\n",
    "#                 out = generator.generate_mesh(data_vis['data'])\n",
    "#             # Get statistics\n",
    "#             try:\n",
    "#                 mesh, stats_dict = out\n",
    "#             except TypeError:\n",
    "#                 mesh, stats_dict = out, {}\n",
    "\n",
    "#             mesh.export(os.path.join(out_dir, 'vis', '{}_{}_{}.off'.format(it, data_vis['category'], data_vis['it'])))\n",
    "\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (checkpoint_every > 0 and (it % checkpoint_every) == 0):\n",
    "        print('Saving checkpoint')\n",
    "        checkpoint_io.save('metropolis+sigma1.pt', epoch_it=epoch_it, it=it)\n",
    "\n",
    "    # Backup if necessary\n",
    "    if (backup_every > 0 and (it % backup_every) == 0):\n",
    "        print('Backup checkpoint')\n",
    "        checkpoint_io.save('metropolis+sigma1Model_%d.pt' % it, epoch_it=epoch_it, it=it)\n",
    "        \n",
    "    # Run validation\n",
    "#     if validate_every > 0 and (it % validate_every) == 0:\n",
    "#         eval_dict = trainer.evaluate(val_loader)\n",
    "#         metric_val = eval_dict[model_selection_metric]\n",
    "#         print('Validation metric (%s): %.4f'\n",
    "#                 % (model_selection_metric, metric_val))\n",
    "\n",
    "#         for k, v in eval_dict.items():\n",
    "#             logger.add_scalar('val/%s' % k, v, it)\n",
    "\n",
    "#         if model_selection_sign * (metric_val - metric_val_best) > 0:\n",
    "#             metric_val_best = metric_val\n",
    "#             print('New best model (loss %.4f)' % metric_val_best)\n",
    "#             checkpoint_io.save('model_best.pt', epoch_it=epoch_it, it=it,\n",
    "#                                 loss_val_best=metric_val_best)\n",
    "\n",
    "    # Exit if necessary\n",
    "#     if exit_after > 0 and (time.time() - t0) >= exit_after:\n",
    "#         print('Time limit reached. Exiting.')\n",
    "#         checkpoint_io.save('model.pt', epoch_it=epoch_it, it=it,\n",
    "#                             loss_val_best=metric_val_best)\n",
    "\n",
    "#print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b4541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv_onet",
   "language": "python",
   "name": "conv_onet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
