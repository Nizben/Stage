{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2142cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time, datetime\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "from src import config, data\n",
    "from src.checkpoints import CheckpointIO\n",
    "from collections import defaultdict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cb003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config.load_config('configs/pointcloud/grid.yaml', 'configs/default.yaml')\n",
    "is_cuda = (torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e1ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Shorthands\n",
    "out_dir = cfg['training']['out_dir']\n",
    "batch_size = cfg['training']['batch_size']\n",
    "backup_every = cfg['training']['backup_every']\n",
    "vis_n_outputs = cfg['generation']['vis_n_outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab4b41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_metric = cfg['training']['model_selection_metric']\n",
    "if cfg['training']['model_selection_mode'] == 'maximize':\n",
    "    model_selection_sign = 1\n",
    "elif cfg['training']['model_selection_mode'] == 'minimize':\n",
    "    model_selection_sign = -1\n",
    "else:\n",
    "    raise ValueError('model_selection_mode must be '\n",
    "                     'either maximize or minimize.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19dfcda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'points': array([[-0.04952807,  0.4819259 ,  0.01673259],\n",
      "       [-0.03787785,  0.41909906,  0.20245078],\n",
      "       [-0.5370819 , -0.35882676,  0.12334375],\n",
      "       ...,\n",
      "       [-0.5018162 ,  0.49840465,  0.43694407],\n",
      "       [-0.48304105, -0.17943507, -0.28516206],\n",
      "       [ 0.02512551, -0.42349476, -0.3951674 ]], dtype=float32), 'points.occ': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'inputs': array([[ 0.15783691,  0.04495239,  0.34887695],\n",
      "       [ 0.1274414 ,  0.31152344,  0.2211914 ],\n",
      "       [ 0.16784668,  0.30493164,  0.0035305 ],\n",
      "       ...,\n",
      "       [-0.14587402,  0.34545898,  0.03475952],\n",
      "       [-0.12158203,  0.34716797,  0.3635254 ],\n",
      "       [ 0.2548828 ,  0.34228516,  0.23010254]], dtype=float32), 'inputs.normals': array([[ 0.15515137,  0.17016602, -0.97314453],\n",
      "       [-0.6464844 , -0.7626953 ,  0.01418304],\n",
      "       [ 0.64746094, -0.76123047, -0.03527832],\n",
      "       ...,\n",
      "       [-0.07946777,  0.9921875 ,  0.09643555],\n",
      "       [-0.1697998 ,  0.98095703,  0.09606934],\n",
      "       [ 0.34716797,  0.9379883 , -0.00556183]], dtype=float32)}\n",
      "<src.data.core.Shapes3dDataset object at 0x7fd76d36b080>\n",
      "2048\n",
      "5958\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "shutil.copyfile('configs/pointcloud/grid.yaml', os.path.join(out_dir, 'config.yaml'))\n",
    "\n",
    "# Dataset\n",
    "train_dataset = config.get_dataset('train', cfg)\n",
    "val_dataset = config.get_dataset('val', cfg, return_idx=True)\n",
    "print(train_dataset[5])\n",
    "print(train_dataset)\n",
    "print(len(train_dataset[5]['points.occ']))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e9d7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fd76d6d0ac8>\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset[5], batch_size=batch_size, num_workers=cfg['training']['n_workers'], shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "\n",
    "print(len(train_loader))    \n",
    "print(train_loader)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=1, num_workers=cfg['training']['n_workers_val'], shuffle=False,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed78165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amine code subset\n",
    "\n",
    "train_dataset = config.get_dataset(‘val’, cfg)\n",
    "ds = torch.utils.data.Subset(train_dataset, indices= [0]*len(train_dataset))\n",
    "val_dataset = config.get_dataset(‘val’, cfg)\n",
    "#val_ds = torch.utils.data.Subset(val_dataset, indices= [0]*len(val_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=16, num_workers=8, shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=1, num_workers=8, shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af74c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizations\n",
    "vis_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=1, shuffle=False,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "model_counter = defaultdict(int)\n",
    "data_vis_list = []\n",
    "\n",
    "# Build a data dictionary for visualization\n",
    "iterator = iter(vis_loader)\n",
    "for i in range(len(vis_loader)):\n",
    "    data_vis = next(iterator)\n",
    "    idx = data_vis['idx'].item()\n",
    "    model_dict = val_dataset.get_model_dict(idx)\n",
    "    category_id = model_dict.get('category', 'n/a')\n",
    "    category_name = val_dataset.metadata[category_id].get('name', 'n/a')\n",
    "    category_name = category_name.split(',')[0]\n",
    "    if category_name == 'n/a':\n",
    "        category_name = category_id\n",
    "\n",
    "    c_it = model_counter[category_id]\n",
    "    if c_it < vis_n_outputs:\n",
    "        data_vis_list.append({'category': category_name, 'it': c_it, 'data': data_vis})\n",
    "\n",
    "    model_counter[category_id] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bf4b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/pointcloud/grid/model.pt\n",
      "=> Loading checkpoint from local file...\n",
      "Current best validation metric (iou): 0.04091307\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = config.get_model(cfg, device=device, dataset=train_dataset)\n",
    "\n",
    "# Generator\n",
    "generator = config.get_generator(model, cfg, device=device)\n",
    "\n",
    "# Intialize training\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "trainer = config.get_trainer(model, optimizer, cfg, device=device)\n",
    "\n",
    "checkpoint_io = CheckpointIO(out_dir, model=model, optimizer=optimizer)\n",
    "try:\n",
    "    load_dict = checkpoint_io.load('model.pt')\n",
    "except FileExistsError:\n",
    "    load_dict = dict()\n",
    "epoch_it = load_dict.get('epoch_it', 0)\n",
    "it = load_dict.get('it', 0)\n",
    "metric_val_best = load_dict.get(\n",
    "    'loss_val_best', -model_selection_sign * np.inf)\n",
    "\n",
    "if metric_val_best == np.inf or metric_val_best == -np.inf:\n",
    "    metric_val_best = -model_selection_sign * np.inf\n",
    "print('Current best validation metric (%s): %.8f'\n",
    "      % (model_selection_metric, metric_val_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa0f2ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1978209\n",
      "output path:  out/pointcloud/grid\n"
     ]
    }
   ],
   "source": [
    "# Shorthands\n",
    "print_every = cfg['training']['print_every']\n",
    "checkpoint_every = cfg['training']['checkpoint_every']\n",
    "validate_every = cfg['training']['validate_every']\n",
    "visualize_every = cfg['training']['visualize_every']\n",
    "\n",
    "# Print model\n",
    "nparameters = sum(p.numel() for p in model.parameters())\n",
    "print('Total number of parameters: %d' % nparameters)\n",
    "\n",
    "print('output path: ', cfg['training']['out_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bc831ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nKeyError: 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c818d10ecf36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mepoch_it\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepoch_it\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nKeyError: 3\n"
     ]
    }
   ],
   "source": [
    "batch = next(train_loader.__iter__())\n",
    "while epoch_it<10000:\n",
    "    epoch_it += 1\n",
    "\n",
    "    it += 1\n",
    "    loss = trainer.train_step(batch)\n",
    "    #logger.add_scalar('train/loss', loss, it)\n",
    "\n",
    "    # Print output\n",
    "    if print_every > 0 and (it % print_every) == 0:\n",
    "        t = datetime.datetime.now()\n",
    "        print('[Epoch %02d] it=%03d, loss=%.4f, time: %.2fs, %02d:%02d'\n",
    "                    % (epoch_it, it, loss, time.time() - t0, t.hour, t.minute))\n",
    "\n",
    "    #data_v = next(in data_vis_.__iter__())ist:\n",
    "    # Visualize output\n",
    "    if visualize_every > 0 and (it % visualize_every) == 0:\n",
    "        print('Visualizing')\n",
    "        for data_vis in data_vis_list:\n",
    "            if cfg['generation']['sliding_window']:\n",
    "                out = generator.generate_mesh_sliding(data_vis['data'])    \n",
    "            else:\n",
    "                out = generator.generate_mesh(data_vis['data'])\n",
    "            # Get statistics\n",
    "            try:\n",
    "                mesh, stats_dict = out\n",
    "            except TypeError:\n",
    "                mesh, stats_dict = out, {}\n",
    "\n",
    "            mesh.export(os.path.join(out_dir, 'vis', '{}_{}_{}.off'.format(it, data_vis['category'], data_vis['it'])))\n",
    "\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (checkpoint_every > 0 and (it % checkpoint_every) == 0):\n",
    "        print('Saving checkpoint')\n",
    "        checkpoint_io.save('model.pt', epoch_it=epoch_it, it=it,\n",
    "                            loss_val_best=metric_val_best)\n",
    "\n",
    "    # Backup if necessary\n",
    "    if (backup_every > 0 and (it % backup_every) == 0):\n",
    "        print('Backup checkpoint')\n",
    "        checkpoint_io.save('model_%d.pt' % it, epoch_it=epoch_it, it=it,\n",
    "                            loss_val_best=metric_val_best)\n",
    "    # Run validation\n",
    "    if validate_every > 0 and (it % validate_every) == 0:\n",
    "        eval_dict = trainer.evaluate(val_loader)\n",
    "        metric_val = eval_dict[model_selection_metric]\n",
    "        print('Validation metric (%s): %.4f'\n",
    "                % (model_selection_metric, metric_val))\n",
    "\n",
    "#         for k, v in eval_dict.items():\n",
    "#             logger.add_scalar('val/%s' % k, v, it)\n",
    "\n",
    "        if model_selection_sign * (metric_val - metric_val_best) > 0:\n",
    "            metric_val_best = metric_val\n",
    "            print('New best model (loss %.4f)' % metric_val_best)\n",
    "            checkpoint_io.save('model_best.pt', epoch_it=epoch_it, it=it,\n",
    "                                loss_val_best=metric_val_best)\n",
    "\n",
    "    # Exit if necessary\n",
    "#     if exit_after > 0 and (time.time() - t0) >= exit_after:\n",
    "#         print('Time limit reached. Exiting.')\n",
    "#         checkpoint_io.save('model.pt', epoch_it=epoch_it, it=it,\n",
    "#                             loss_val_best=metric_val_best)\n",
    "\n",
    "#print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaff508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yaml    model_2600.pt  model_3500.pt  model_4400.pt  model_5300.pt\r\n",
      "model_1800.pt  model_2700.pt  model_3600.pt  model_4500.pt  model_5400.pt\r\n",
      "model_1900.pt  model_2800.pt  model_3700.pt  model_4600.pt  model_5500.pt\r\n",
      "model_2000.pt  model_2900.pt  model_3800.pt  model_4700.pt  model_5600.pt\r\n",
      "model_2100.pt  model_3000.pt  model_3900.pt  model_4800.pt  model_5700.pt\r\n",
      "model_2200.pt  model_3100.pt  model_4000.pt  model_4900.pt  model_best.pt\r\n",
      "model_2300.pt  model_3200.pt  model_4100.pt  model_5000.pt  model.pt\r\n",
      "model_2400.pt  model_3300.pt  model_4200.pt  model_5100.pt  \u001b[0m\u001b[01;34mvis\u001b[0m/\r\n",
      "model_2500.pt  model_3400.pt  model_4300.pt  model_5200.pt\r\n"
     ]
    }
   ],
   "source": [
    "def ascent(p, model, num_steps):\n",
    "    for t in range(num_steps):\n",
    "        p += alpha*model(p)/2 + torch.randn(p.shape)*torch.sqrt(alpha)\n",
    "        return p \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea8730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d864c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv_onet",
   "language": "python",
   "name": "conv_onet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
