{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2142cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time, datetime\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "from src import config, data\n",
    "from src.checkpoints import CheckpointIO\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "cfg = config.load_config('configs/pointcloud/grid.yaml', 'configs/default.yaml')\n",
    "is_cuda = (torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Shorthands\n",
    "out_dir = cfg['training']['out_dir']\n",
    "batch_size = cfg['training']['batch_size']\n",
    "backup_every = cfg['training']['backup_every']\n",
    "vis_n_outputs = cfg['generation']['vis_n_outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4b41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_metric = cfg['training']['model_selection_metric']\n",
    "if cfg['training']['model_selection_mode'] == 'maximize':\n",
    "    model_selection_sign = 1\n",
    "elif cfg['training']['model_selection_mode'] == 'minimize':\n",
    "    model_selection_sign = -1\n",
    "else:\n",
    "    raise ValueError('model_selection_mode must be '\n",
    "                     'either maximize or minimize.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19dfcda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'points': array([[ 0.28653923, -0.12025055, -0.14390461],\n",
      "       [-0.5053949 , -0.17336729,  0.42622212],\n",
      "       [ 0.01185322,  0.46338594, -0.38767037],\n",
      "       ...,\n",
      "       [-0.03744983,  0.07267402, -0.2433695 ],\n",
      "       [ 0.06046839,  0.36615038,  0.03766698],\n",
      "       [-0.12901546, -0.03184857, -0.06972388]], dtype=float32), 'points.occ': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'points.dist': array([0.23416527, 0.315751  , 0.11779001, ..., 0.15722497, 0.01545486,\n",
      "       0.20757586], dtype=float32), 'points.closest_points': array([[ 0.16247559, -0.11517334, -0.3425293 ],\n",
      "       [-0.19494629, -0.16687012,  0.36889648],\n",
      "       [ 0.00832367,  0.3479004 , -0.3647461 ],\n",
      "       ...,\n",
      "       [-0.15625   ,  0.07171631, -0.3461914 ],\n",
      "       [ 0.06195068,  0.35083008,  0.0375061 ],\n",
      "       [-0.01806641, -0.20690918, -0.07672119]], dtype=float32), 'inputs': array([[-0.01168823,  0.32836914, -0.03408813],\n",
      "       [ 0.12878418,  0.34521484,  0.31298828],\n",
      "       [-0.14733887,  0.34594727,  0.01221466],\n",
      "       ...,\n",
      "       [ 0.21350098,  0.34594727, -0.06134033],\n",
      "       [ 0.1307373 ,  0.30737305,  0.16113281],\n",
      "       [-0.01235199,  0.32836914, -0.0814209 ]], dtype=float32), 'inputs.normals': array([[-0.0760498 , -0.9970703 ,  0.01524353],\n",
      "       [-0.27929688,  0.9589844 , -0.05291748],\n",
      "       [-0.03442383,  0.9995117 ,  0.01072693],\n",
      "       ...,\n",
      "       [ 0.07177734,  0.99316406, -0.09289551],\n",
      "       [-0.71435547, -0.6899414 , -0.11486816],\n",
      "       [-0.00459671, -1.        ,  0.00844574]], dtype=float32), 'inputs.kdtree_points': array([[ 0.1105957 ,  0.34814453, -0.0209198 ],\n",
      "       [ 0.13024902,  0.32104492,  0.44750977],\n",
      "       [-0.06500244,  0.3269043 , -0.32885742],\n",
      "       ...,\n",
      "       [ 0.15905762, -0.31445312,  0.38256836],\n",
      "       [ 0.25512695,  0.34277344,  0.28466797],\n",
      "       [-0.15234375, -0.19616699,  0.37036133]], dtype=float32)}\n",
      "<src.data.core.Shapes3dDataset object at 0x7f40e7198e48>\n",
      "2048\n",
      "5958\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "shutil.copyfile('configs/pointcloud/grid.yaml', os.path.join(out_dir, 'config.yaml'))\n",
    "\n",
    "# Dataset\n",
    "train_dataset = config.get_dataset('train', cfg)\n",
    "val_dataset = config.get_dataset('val', cfg, return_idx=True)\n",
    "print(train_dataset[5])\n",
    "print(train_dataset)\n",
    "print(len(train_dataset[5]['points.occ']))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42160475",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9d7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset[5], batch_size=batch_size, num_workers=cfg['training']['n_workers'], shuffle=True,\n",
    "#     collate_fn=data.collate_remove_none,\n",
    "#     worker_init_fn=data.worker_init_fn)\n",
    "\n",
    "# print(len(train_loader))    \n",
    "# print(train_loader)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset, batch_size=1, num_workers=cfg['training']['n_workers_val'], shuffle=False,\n",
    "#      collate_fn=data.collate_remove_none,\n",
    "#      worker_init_fn=data.worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60799253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amine code subset\n",
    "\n",
    "train_dataset = config.get_dataset(\"train\", cfg)\n",
    "ds = torch.utils.data.Subset(train_dataset, indices= [0]*len(train_dataset))\n",
    "val_dataset = config.get_dataset(\"val\", cfg)\n",
    "val_ds = torch.utils.data.Subset(val_dataset, indices= [0]*len(val_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=32, num_workers=8, shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     ds, batch_size=1, num_workers=8, shuffle=True,\n",
    "#     collate_fn=data.collate_remove_none,\n",
    "#     worker_init_fn=data.worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf4b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = config.get_model(cfg, device=device, dataset=train_dataset)\n",
    "\n",
    "# Generator\n",
    "generator = config.get_generator(model, cfg, device=device)\n",
    "\n",
    "# Intialize training\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "trainer = config.get_trainer(model, optimizer, cfg, device=device)\n",
    "\n",
    "checkpoint_io = CheckpointIO(out_dir, model=model, optimizer=optimizer)\n",
    "# try:\n",
    "#     load_dict = checkpoint_io.load('model.pt')\n",
    "# except FileExistsError:\n",
    "#     load_dict = dict()\n",
    "# epoch_it = load_dict.get('epoch_it', 0)\n",
    "# it = load_dict.get('it', 0)\n",
    "# metric_val_best = load_dict.get(\n",
    "#      'loss_val_best', -model_selection_sign * np.inf)\n",
    "\n",
    "# if metric_val_best == np.inf or metric_val_best == -np.inf:\n",
    "#     metric_val_best = -model_selection_sign * np.inf\n",
    "# print('Current best validation metric (%s): %.8f'\n",
    "#       % (model_selection_metric, metric_val_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0f2ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1978275\n",
      "output path:  out/pointcloud/grid\n"
     ]
    }
   ],
   "source": [
    "# Shorthands\n",
    "print_every = cfg['training']['print_every']\n",
    "checkpoint_every = cfg['training']['checkpoint_every']\n",
    "validate_every = cfg['training']['validate_every']\n",
    "visualize_every = cfg['training']['visualize_every']\n",
    "\n",
    "# Print model\n",
    "nparameters = sum(p.numel() for p in model.parameters())\n",
    "print('Total number of parameters: %d' % nparameters)\n",
    "\n",
    "print('output path: ', cfg['training']['out_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5e936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nizar/miniconda3/envs/conv_onet/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "c = model.encode_inputs(batch.get('inputs').cuda())\n",
    "results = model.decode(batch.get('points').cuda(), c).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418a568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05e2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc831ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2048])\n",
      "torch.Size([32, 2048, 1000])\n",
      "torch.Size([32, 2048])\n",
      "torch.Size([32, 2048])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2048) must match the size of tensor b (1000) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-47890036ad7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#logger.add_scalar('train/loss', loss, it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testBS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/convolutional_occupancy_networks/src/conv_onet/trainingtest.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/convolutional_occupancy_networks/src/conv_onet/trainingtest.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mterme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md_k1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq_0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mq_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2048) must match the size of tensor b (1000) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "epoch_it = 0\n",
    "batch = next(train_loader.__iter__())\n",
    "while epoch_it<5000:\n",
    "    epoch_it += 1\n",
    "\n",
    "    it += 1\n",
    "    loss = trainer.train_step(batch)\n",
    "    #logger.add_scalar('train/loss', loss, it)\n",
    "    writer.add_scalar(\"testBS\", loss[0], it)\n",
    "\n",
    "    # Print output\n",
    "    if print_every > 0 and (it % print_every) == 0:\n",
    "        t = datetime.datetime.now()\n",
    "        print('[Epoch %02d] it=%03d, loss=%.4f, time: %.2fs, %02d:%02d'\n",
    "                    % (epoch_it, it, loss[0], time.time() - t0, t.hour, t.minute))\n",
    "\n",
    "    #data_v = next(in data_vis_.__iter__())ist:\n",
    "    # Visualize output\n",
    "    if visualize_every > 0 and (it % visualize_every) == 0:\n",
    "        print('Visualizing')\n",
    "        for data_vis in data_vis_list:\n",
    "            if cfg['generation']['sliding_window']:\n",
    "                out = generator.generate_mesh_sliding(data_vis['data'])\n",
    "            else:\n",
    "                out = generator.generate_mesh(data_vis['data'])\n",
    "            # Get statistics\n",
    "            try:\n",
    "                mesh, stats_dict = out\n",
    "            except TypeError:\n",
    "                mesh, stats_dict = out, {}\n",
    "\n",
    "            mesh.export(os.path.join(out_dir, 'vis', '{}_{}_{}.off'.format(it, data_vis['category'], data_vis['it'])))\n",
    "\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (checkpoint_every > 0 and (it % checkpoint_every) == 0):\n",
    "        print('Saving checkpoint')\n",
    "        checkpoint_io.save('testBS.pt', epoch_it=epoch_it, it=it)\n",
    "\n",
    "    # Backup if necessary\n",
    "    if (backup_every > 0 and (it % backup_every) == 0):\n",
    "        print('Backup checkpoint')\n",
    "        checkpoint_io.save('testBS_%d.pt' % it, epoch_it=epoch_it, it=it)\n",
    "        \n",
    "    # Run validation\n",
    "#     if validate_every > 0 and (it % validate_every) == 0:\n",
    "#         eval_dict = trainer.evaluate(val_loader)\n",
    "#         metric_val = eval_dict[model_selection_metric]\n",
    "#         print('Validation metric (%s): %.4f'\n",
    "#                 % (model_selection_metric, metric_val))\n",
    "\n",
    "#         for k, v in eval_dict.items():\n",
    "#             logger.add_scalar('val/%s' % k, v, it)\n",
    "\n",
    "#         if model_selection_sign * (metric_val - metric_val_best) > 0:\n",
    "#             metric_val_best = metric_val\n",
    "#             print('New best model (loss %.4f)' % metric_val_best)\n",
    "#             checkpoint_io.save('model_best.pt', epoch_it=epoch_it, it=it,\n",
    "#                                 loss_val_best=metric_val_best)\n",
    "\n",
    "    # Exit if necessary\n",
    "#     if exit_after > 0 and (time.time() - t0) >= exit_after:\n",
    "#         print('Time limit reached. Exiting.')\n",
    "#         checkpoint_io.save('model.pt', epoch_it=epoch_it, it=it,\n",
    "#                             loss_val_best=metric_val_best)\n",
    "\n",
    "#print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d4ef18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv_onet",
   "language": "python",
   "name": "conv_onet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
